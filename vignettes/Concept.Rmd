---
title: "AutoPollen - Implementierung der Daten in die Prognosemodelle"
author: "Simon Adamov"
date: "7/13/2020"
output: html_document
---

```{r echo = FALSE}
knitr::opts_chunk$set(echo = FALSE,
                      error = FALSE, 
                      warning = FALSE, 
                      message = FALSE,
                      fig.retina =3,
                      fig.width = 10,
                      fig.height = 7,
                      fig.align = "center",
                      out.width = "100%",
                      out.height = "100%")
```

# Einleitung

Im Projekt CHAPo werden automatische Pollenmessgeräte auf dem ganzem Gebiet der Schweiz installiert. Diese neuartigen Fallen werden von der Firma Swisens produziert und tragen den Namen Poleno. Der grosse Vorteil für die Prognose-Modelle liegt in der Verfügbarkeit der Daten; diese werden ab 2021 in Echtzeit an das Rechenzentrum der Meteoschweiz gesendet. Zudem konnten die Poleno Fallen in einem ersten Vergleich auch zeigen, dass sie bereits bei geringeren Pollen-Konzentrationen robuste Messungen ermöglichen. In bisherigen Analysen wurden die Roadmap und die Messorte für die neuen Fallen definiert. Dieses Dokument soll aufweisen inwiefern die Prognose-Modelle am meisten von den neuen Daten profitieren können. Dazu werden Module und Code-Stellen der Cosmo Code-Datenbank ausgewählt, die am ehesten von den zeitlich höher aufgelösten Daten profitieren könnten.

Generell werden folgende Fragestellungen geklärt werden müssen:

- Welche Parameter / Funktionen sollen von der neuen Daten Assimilation profitieren?
- Wie häufig soll der jeweilge Parameter / Funktion an die momentanen Messwerte angepasst werden?
- Kann dieselbe Methode für alle relevanten Pollentaxa verwendet werden?
- Wie soll räumlich zwischen den rund 20 Stationen interpoliert werden?
- Wie kann die Güte der neuen Methoden überprüft werden (was dient als "Ground-Truth")?
- Wird die maximale Pollenemission pro Tag durch die neuen Daten aufgeweicht?
- Wie schnell sind Messwerte verfügbar?

# Module und Code-Auszüge

Die Pollen sind anhand des folgenden Schemas in COSMO-ART implementiert.

```{r}
knitr::include_graphics("figures/diagram_implementation.png")
```

Die Bedeutung der Symbole und das Diagramm stammen von Zink, 2014.

```{r out.width="75%"}
knitr::include_graphics("figures/parameters.png")
```

Folgende Teilgebiete der Pollen-Implementierung könnten von den neuen Echtzeit-Daten profitieren und sind verantwortlich für den grössten Teil der Unsicherheiten in der numerischen Pollenvorhersage:

- Phänologie: Beginn/Ende der Pollensaison von den real-time Pollendaten triggern (oder verhindern) lassen (z.B. via neu variables Feld der kritischen T-summe)
- Stärke der Pollensaison: Mast- und Samenjahren (indirekte Skalierung der Verbreitungskarte), Ein Tuning-Faktor wird bei runtime immer definiert. 

Die modellierte Pollenkonzentration in der Luft kann dabei nicht einfach näher an die Messwerte gezogen werden (Nudging der Messwerte), da diese Information schnell verloren geht, vielmehr müssen Emissions-Parameter angepasst werden (Nudging der Parameter).

Die folgenden beiden Parameter kommen als Kandidaten für Echtzeit Anpassungen in Frage:

- Fraction of the grid box covered with the specific plant \\(f_{Q,cov}\\)
- Mathematical description of the course of the pollen season \\(f_{Q,seas}\\)

Der erste der beiden Parameter wird dem Modell als Grid-Inputfeld bereit gestellt (Verbreitungskarte). Es kommen sowohl direkte Skalierung dieses Feldes in Frage als auch indirekte Skalierung nachdem das Feld bereit gestellt wurden. Momentan scheint letztere Option die einfachere zu sein, da die indirekte Skalierung bei jedem Modelllauf und Zeitschritt durchgeführt werden kann. Der zweite Parameter, die Saisonalität der Pollenphänologie, wird im Modul pol_seasons jeweils berechnet und kann direkt optimiert werden.

Das übergeschaltete Modul im Pollen-Code heisst "organize_pollen", das eine grosse Anzahl Subroutinen des Pollen-Codes aufruft.

```{r}
knitr::include_graphics("figures/organize_pollen_cgraph.png")
```

Die beiden oben genannten Parameter werden also über den folgenden Weg aufgerufen:

- lmorg -> organize_pollen -> pol_emissions::emiss_p -> emiss_formula_helbig (veraltet)
- lmorg -> organize_pollen -> pol_emissions::emiss_p -> emiss_formula_zink
- lmorg -> organize_pollen -> pol_seasons::calc_saisl

Die erste wird nicht mehr benutzt, da Zink bessere Resultate liefert.
Da wir im Emissionsteil arbeiten werden, genügt es die Gitterboxen am nächsten am Boden zu berücksichtigen (2D-Raster). Die kostspielige 3D Simulation passiert erst im nächsten Schritt, der in diesem Projekt nicht abgeändert wird.

## Die Daten

Die Echtzeit-Daten der Poleno-Geräte können im Modul data_pollen geladen werden. MDS ist verantwortlich für eine technisch robuste Bereitstellung der Messungen. Momentan werden die Pollen-Messungen nicht für die Prognose verwendet. Eine Pipeline dafür muss also zuerst errichtet und die Schnittstellen definiert werden.

## Die Verbreitungskarte

Wie oben erwähnt wird nicht die Karte direkt skaliert sondern viel eher könnte Pol_tuning immer bei runtime definiert werden. Beispielsweise für Birke wurde bis anhin 1.0166E7_wp Konstanter Faktor definiert für das ganze Feld. Anhand dieses Faktors wird no_max_day, die maximale Anzahl emittierter Pollenkörner definiert.

```{fortran eval = FALSE, echo = TRUE}
! PLANT DEPENDENT VALUES FOR BIRCH
! isp = 1
!----------------------------------
!     dp(lbetu) = 29._wp
!     dd(lbetu) = 26._wp
!     rhop(lbetu) = 751.6_wp
!     d_min(lbetu) = 25._wp
!     d_max(lbetu) = 27._wp
      lai_plant(lbetu) = 3._wp
      hcan(lbetu) = 22._wp

! blooming time during the day:
! Option to switch off emission during specified time.
      tbloom(lbetu,:) = 1._wp              !1 = on, 0 = off
      DO  l=6,18
        tbloom(lbetu,l) = 1._wp
      ENDDO

!     num_pol(lbetu) = 8.944_wp*1.E6_wp
      num_pol(lbetu) = 7.244_wp*1.E6_wp

      tte(lbetu) = 281._wp
      rhte(lbetu) = 0.6_wp
      vbte(lbetu) = 2.9_wp
      c1(lbetu) = 1._wp
      c2(lbetu) = 1._wp
      c3(lbetu) = 1._wp

      ! start day for temperature sum minus 1. CAUTION: Day 1 is 1.Dec!
      jul_days_excl(lbetu) = 40_iintegers   ! value from optimized start of flowering model
                                           ! Definition of the start of flowering: Pollen>30

      ! pollen-specific base temperature for temperature sum (in deg. C)
      t_base(lbetu) = 9._wp            ! value from optimized start of flowering model
                                           ! Definition of the start of flowering: Pollen>30

      ! Maximum number of pollen that can be produced on one m2 during one day.
      ! Estimation for birch: 1000xPOAC
      ! overall tuning factor for Zink emission formula. 1.105: tuning for 2015 based on
      ! CH stations 2014. 0.92: potential for birch pollen in 2015
      !no_max_day(lbetu) = 1.105_wp*1.E9_wp*0.92_wp * pol_tuning(1)
      no_max_day(lbetu) = 1.0166E7_wp * pol_tuning(1)

      ! Maximum number of pollen is reached after 16 h under ideal conditions.
      ! Estimation for birch: 1000xPOAC
      no_max_timestep(lbetu) = no_max_day(lbetu)*dtpollen /(16._wp*3600._wp)

      ! Loss of pollen from the reservoir due to random processes (Animals, ...) per timestep:
      ! Half-life of 43200 seconds (= 12 hours) when only random processes exist.
      ! was: Psi_others(lbetu) = log(2._wp) * dtpollen / (12._wp * 3600._wp)
      !psi_others(lbetu) = exp(log(0.5_wp) * dtpollen / 43200._wp)
      psi_random(lbetu) = exp(log(0.5_wp) * dtpollen / 43200._wp)

      ! Suppression of emission in the aftermath of precipitation:
      ! Evaporation set to 0 when rel. hum. is 100%
      ! Drying needs x hours when rel. hum. is y%
      ! Leads to the formula: coeff = x * (1 - y)
      ! Here: coeff = 3 * (1 - 0.3) = 2.1
      xi_r_precip(lbetu) = 1._wp !if set to 0, no suppression of emission after precipitation
      frac_xi_evap(lbetu) = xi_r_precip(lbetu) * dtpollen / (2.1_wp * 3600._wp)
```

Im code oberhalb wird pol_tuning definiert und mit einem konstanten Wert für Birkenpollen multipliziert (anderer Wert für jede Spezies). Dadurch wird die Variable no_max_day definiert welche dann im pol_emissions Modul wieder aufgerufen wird. Wenn man nun diesen Tuning Faktor variabel für jede Gitterbox und jeden Zeitschritt definiert, kann die maximale Anzahl zu emittierender Pollenkörner max_emiss_day direkt angepasst werden.

```{fortran eval = FALSE, echo = TRUE}
!...........................................................
  ! Biological influence:
  !...........
  ! Determines the maximum amount of pollen that can be produced per day.
  ! The switch 'Phi_biol' is 1 if this amount hasnt been reached, and
  ! turns to 0 as soon as the maximum possible amount has been released
  ! from the flowers into the reservoir on a given day.
  ! The value of this daily maximum depends on the time of year. Thus, the
  ! calculation of 'Phi_biol' requires a description of the pollen season
  ! which is called 'SDES'. 'SDES' is between 0 and 1, the
  ! height of the maximum is determined by 'no_max_day'.
  !...........
  
  
  max_emiss_day = f_q_seas(i,j,isp) * no_max_day(isp) * &
       f_q_cov(i,j,isp) * f_q_alt(i,j,isp)
  
  IF (res_new_sum(i,j,isp) .LT. max_emiss_day) THEN
    phi_biol = 1._wp
  ELSE
    phi_biol = 0._wp
  ENDIF

    
```

Wie man im Code-Teil sehen kann, berechnet sich max_emiss_day anhand vierer Faktoren. Im ersten Schritt haben wir nun no_max_day verändert als Proxy-Skalierung der Verbreitungskarte. Als zweite Option bietet sich die die Variable \\(f_{Q,seas}\\) an.

## Die Saisonalität

Die mathematische Beschreibung der Pollensaison \\(f_{Q,seas}\\) ist dem phänologischen Modell entnommen, das für die operationellen numerischen Pollenvorhersagen an der MeteoSchweiz entwickelt wurde (vgl. Abschnitt 2.3.1). Es wird in beiden Modellkonfigurationen als Eingangsparameter für die Emissionsparametrisierung verwendet. Siehe Abschnitt 3.3.3 in Zinks Dissertation für weitere Informationen. [Zink, 2014]

Im Modul pol_seasons wird \\(f_{Q,seas}\\) bereit gestellt. In der letzten Subroutine des Modules, genannt calc_sdes könnten die zuvor geladenen Echtzeit-Daten implementiert werden. An dieser Stelle könnten zwei Temperatursummerfelder optimiert werden und variabel gemacht werden (tthrs_red and tthrs). Diese beiden Felder existieren bereits im Code sind aber zeitlich fixiert.

```{fortran eval = FALSE, echo = TRUE}
MODULE pol_seasons

!This module calculates the phenological state of the plants (Variable f_q_seas) that
!is used in the pollen emission calculation (module pol_emissions). f_q_seas is zero
!before and after the pollen season. During the pollen season it ranges from
!zero and  (almost) one. The higher f_q_seas the more plants are flowering.
!
!The current implementation includes birch, alder and grasses. For birch and alder, a temperature
!sum model for the start and the end of the pollen season is provided. This model is optimized
!for Swiss pollen data. For grasses, the implemented approach includes a temperature sum model
!for the start of the pollen season. The end of the pollen season is calculated via the
!climatological length of the grass pollen season. Most of the subroutines can
!handle further species some have to be adapted though. For one further species
!(Ambrosia or any other) the structures are already implemented.

USE data_pollen,        ONLY: isp, isp_pollen, var_pollen, jul_days_excl, t_base, &
                              ctsum, t2m_act_field_path, t2m_clim_stns_path,      &
                              tthrs, tthre, f_q_seas, saisn, saisa,               &
                              saisl, dtpollen

SUBROUTINE calc_saisl(ierrstat)

  ! The calculations of this subroutine use station data that are located on the whole domain.
  
  CALL READ_ATAB(file,nrow,lablen,icol,fcol,ncol,rlabel,           &
               iarray,farray,array,rclabel,ilabel,flabel,alabel, &
               header_info,iostat,iomsg)

  ! calculate the length of the season at the 31 stations using a) saisn, b) ctsum,
  ! c) clim. station t2m data gather fields to select t2m values at stations
  CALL gather_field (ctsum    (:,:,isp), ie,je, ctsum_tot, ie_tot,je_tot, -1, ierrstat)
  CALL gather_field (saisa    (:,:,isp), ie,je, saisa_tot, ie_tot,je_tot, -1, ierrstat)
  CALL gather_field (tthrs_red(:,:,isp), ie,je, thr_s_tot, ie_tot,je_tot, -1, ierrstat)
  CALL gather_field (tthre    (:,:,isp), ie,je, thr_e_tot, ie_tot,je_tot, -1, ierrstat)

END SUBROUTINE calc_saisl

```

# Interpolation

Wir werden also zwei Gitterfelder berechnen für die Implementierung der Echtzeit Daten. Zum einen werden wir das kritische Temperatursummenfeld variabel berechnen. Zum anderen wird der Tuningparameter für no_max_day auf ein Gitterfeld aufgespannt und variabel berechnet. Während der Implementierung könnte man folgenden Updates vornehmen, in zunehmender Komplexität:

- Die kritischen Temperatursummmen für den Blühbeginn werden in einem Umkreis um die Messtationen hoch- oder runter korrigiert je nachdem ob tatsächlich schon Pollen gemessen werden. Die kozentrischen Kreise können dadurch gerechtfertigt werden, dass die kritische Temperatursumme für den Blühbeginn nicht von der Topographie (MüM) abhängt. Dabei werden die Mess-Grenzwerte so definiert, dass nur lokale Emissionen und keine Transportereignisse berücksichtigt werden.
- In einem nächsten Schritt könnte man zudem Transport-Ereignisse berücksichtigen und die Einzugsgebiete der Messstationen genauer definiert werden. Vorallem für das naheliegende Ausland könnte dies relevant sein (z.B. Transportereignisse von Ambrosia-Pollen von Frankreich).
- Falls noch mehr Zeit vorhanden sein wird, könnte man mit Kriging oder ML die Interpolation überarbeiten. Momentan wird mit inverse distance weighting gearbeitet. Anhand von räumlicher Regression könnten Einflussgebiete der Messtationen besser verstanden und aktualisiert werden. Dabei könnten verschiedene meteorologische Wariablen wie zum Beisiel Wind berücksichtigt werden.

Für den zweiten und dritten Punkt könnten folgende Resourcen hilfreich sein:

- Die Clusteranalyse von APK um grobe Einzugsgebiete der Fallen abzuschätzen.
- ML vs. Standard Methoden: Spatial Statistics mit räumlichen und zeitlichen Autokorrelationen (Andreas Papritz).
- Kriging um die bodennahen Messwerte vorherzusagen und die Ähnlichkeit zu den umliegenden Messstationen zu berechnen.
- https://opengeohub.org/machine-learning-spatial-data für ML Approaches

Herausforderungen und offene Fragen:

- Topographie in Alpen wird potentiell problematisch, da nicht sehr viele Fallen zur Verfügung stehen.
- Wie stark verzögert, wie häufig und in welchem Radius sollen die Emissions-Parameter angepasst werden?

# Validation

- Die statistische Vergleichsstudie von Hirst und Poleno Fallen von APK sollte hier hilfreich sein.
- Welche Validations-Metriken sollen verwendet werden (evtl. auch kategorische)?
    - Erste Methoden sind nun verfügbar, sowohl numerisch als auch kategorischer Natur. Die Kategorien müssten aber noch für jede Spezies definiert werden.
- Soll man Hirst oder Poleno als Ground-Truth anerkennen? 
    - Nur Hirst kommt wirklich in Frage, da auf den Jahren 2017-2020 getestet und getuned wird und Poleno ja erst ab 2021 verfügbar sein wird.
- Zu welchen Zeitpunkten im Jahr soll verifiziert werden?
- Momentan werden Prognosen für 4 Spezies berechnet (Erle, Birke, Gräser, Ambrosia). Werden eventuell noch zusätzliche Spezies analysiert? 
    - Dies ist momentan nicht Priorität und hängt direkt mit den benötigten Rechenresourcen zusammen.

# Anforderungen

- Data Pipeline, um die Echtzeit-Pollendaten abzurufen, Dani fragen (APN), welche Verzögerung noch in Ordnung ist.

   - Für das DWH steht die Pipeline und die Messdaten sind direkt in R verfügbar auf tsa (cscs) und zueub915.
  
    - Das Skript (fieldextra namelist) um die modellierten Pollen-Konzentration von 2017-2020 (Modell-Beginn)abzurufen existiert und ist fast durchgelaufen. Allerdings müsste dieses evtl. noch angepasst werden um Stundenmittelwerte anstatt punktuelle Messwerte abzurufen.
  
    - Dani meinte, dass eine Stunde Verspätung noch okay ist. Dies könnte knapp werden, wenn man das Paper von Galley (2020) berücksichtigt wo anscheinend 3h-Verzögerung beobachtet wurde. *Die KENDA Datenassimilation wird stündlich gerechnet, und es wird ein cut_off von 45min eingehalten. D.h. die Analyse startet frühestens 45min nach der Analysenzeit (also eine 00UTC Analyse wird erst um 00:45UTC gerechnet). Dies, damit genügend Beobachtungen in der Datenbank sind, denn diese brauchen eine bestimmte Zeit, bis sie hier ankommen. Wenn du die Pollendaten in COSMO-1E einbringen möchtest, ist das ein bisschen anders: Wie Du sagst, starten die COSMO-1E Vorhersagen alle 3h und immer um ca Analysezeit plus 1h (die zugehörige KENDA Analyse braucht noch ca 15min). Die Pollenbeobachtungen müssten also um Analysezeit + 1h verfügbar sein, damit sie in COSMO-1E verwendet werden können. Also z.B. für die 00UTC COSMO-1E Vorhersage müssten die Pollenbeobachtungen spätestens um 01UTC vorhanden sein. Beachte, dass unser Schedule immer in UTC läuft und in Sommer- und Winterzeit eine Stunde verschoben in Localtime ist!*
  
    - Gian: *Die Zeitliche Verzögerung über die Schnittstelle am Rohdatenserver ist im Bereich weniger Minuten ( 0-5 min vielleicht). Die Verzögerung in der operationellen Kette übers DWH kennen wir noch nicht da sich diese noch im Aufbau befindet, aber es ist geplant alle 10 Minuten Daten zu liefern. Es werden Pollenkonzentrationen ins DWH übermittelt (10minuten Werte und Stündliche Werte). Die Rohdaten (Events mit Timestamp) werden nur im Rohdatenserver archiviert*
  
- Wo wird die Validierung stattfinden? Ist es am besten, rstudio auf tsa zu installieren? 

    - In R auf zueub915 oder direkt tsa. Auf beiden Systemen ist R 3.5.2 installiert. Die fieldextra namelist muss auf tsa ausgeführt werden und das resultierende csv-file in den Projekt-Ordner kopiert werden.
  
    - Hiermit können die Daten zwischen tsa und zueub915 synchronisiert werden: `rsync -r sadamov@tsa.cscs.ch:/scratch/sadamov/rstudio/CHAPo/vignettes/ext-data /prod/zue/climate/others/ads/CHAPo/vignettes/`
  
- Mit Regula (APK) die Definition von Mast- und Samenjahren besprechen.

    - Simon: *Ich hätte eine generelle Frage zu den Pollenmodellierungen (gar nicht pressant): Mit den neuen Echtzeit-Daten möchten wir ja die modellierten Pollen-Konzentrationen laufend updaten. Ein Problem dabei sind die Mast- und Samenjahre für Betula und Alnus (beide folgen einem 2-Jahres-Rhythmus oder?). Poaceae und Ambrosia folgen ja keinem 2-Jahresrhythmus wenn ich das richtig verstehe. Wir haben nun theoretisch vor, nach den ersten Messungen in der Pollensaison die potentiell «emittierbare» Pollenmenge je nach Jahr und Spezies zu erhöhen oder erniedrigen. Nun zur Frage: Was denkst du, wie lange muss man messen um zu bestimmen ob Betula und Alnus in einem Mast- oder Samenjahr sind. Und falls möglich, wie lange müsste man messen um die Stärke der Pollensaison für diese Spezies noch genauer zu schätzen (also eigentlich einen SPI schätzen nach nur ein paar Tagen Emission)? Wäre super wenn sowas möglich ist.*   
  Regula: *Da stellst du aber ein ganz schwierige Frage. Ich habe das noch nie so überlegt und auch nie Daten dazu angeschaut. Am besten machst du selber gewisse Untersuchungen, z.B. schauen wie der Pollenflug der ersten Tage mit dem SPIn oder der Anzahl Tage mit starkem und sehr starkem Pollenflug korreliert. Ab wieviel Tagen (oder ab wie viel Tagen mit mehr als 70 Pollen) wird die Korrelation besser? Was ich auch nicht genau weiss, ist, ob die Dauer der Pollensaison ebenfalls länger ist, wenn du ein starkes Jahr hast als bei einem schwachen. Was sicher ist, ist, dass bei einem späten Beginn der Birke die Saison eher kurz ist, bei einem frühen tendenziell länger. Aber bei anderen Arten ist das nicht unbedingt so. Wie hat das Modell von Teena mit der Vorhersage des SPIn funktioniert? Braucht Ihr wirklich eine langfristige Anpassung der Emissionskurve oder könnt Ihr diese laufend mit den gemessenen Daten während der Saison anpassen? Auch der 2-Jahreszyklus der Bäume ist nicht immer vorhanden und kann durch verschiedene Einflussfaktoren gestört werden.  Ich kann dir leider so spontan nicht weiter helfen.*
  

- Das gesamte Projekt darf nicht zu teuer werden (~ +5% computing cost)

# Nächste Schritte
 
Implementierung der variablen Felder und erste COSMO Runs! :-)
















